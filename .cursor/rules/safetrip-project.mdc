# SafeTrip Project Development Rules

## Project Overview
SafeTrip은 YOLOv11 기반의 다중 작업 컴퓨터 비전 모델을 개발하여 자율주행 차량의 안전성을 향상시키는 프로젝트입니다.

## Core Technologies

### Framework & Libraries
- **Base Model**: YOLOv11 (Ultralytics 최신 버전)
- **Deep Learning**: PyTorch 2.0+
- **Computer Vision**: OpenCV, Ultralytics
- **Optimization**: TensorRT for Jetson deployment
- **Monitoring**: Weights & Biases, TensorBoard

### Multi-Task Architecture
1. **Object Detection**: 32개 클래스 (person, car, pole, traffic_sign 등)
2. **Instance Segmentation**: 6개 surface 클래스 (alley, sidewalk, roadway 등)  
3. **Depth Estimation**: 스테레오 비전 기반 깊이 추정

## Data Structure & Handling

### Dataset Organization
```
data/
├── bbox/           # Object detection (50 folders, ~14,642 images)
├── surface/        # Segmentation (130 folders, ~9,556 images)
└── depth/          # Depth estimation (5 folders, ~19,721 images)
```

### Annotation Formats
- **BBox**: CVAT XML 형식, 다중 객체 바운딩 박스
- **Surface**: Polygon 좌표, 도로 표면 segmentation
- **Depth**: 스테레오 캘리브레이션 파일 (.conf)

### Data Processing Rules
- Partial labeling 지원 (일부 태스크만 라벨된 데이터 허용)
- 태스크별 데이터 밸런싱 (Detection:Segmentation:Depth = 40:30:30)
- Missing annotation 처리 로직 포함

## Model Development Guidelines

### Architecture Principles
- YOLOv11 기반 통합 아키텍처
- Shared backbone and neck for efficiency
- Task-specific heads for specialized outputs
- Feature reuse 최대화로 메모리 효율성 확보

### Training Strategy
```python
# Phase 1: Head-only training (1-30 epochs)
# - Freeze backbone weights
# - Train custom heads only
# - Higher learning rates

# Phase 2: End-to-end training (31-100 epochs) 
# - Unfreeze all parameters
# - Lower learning rates
# - Fine-tuning entire model
```

### Loss Function Design
- Dynamic loss weighting (Kendall et al. uncertainty method)
- Task-aware masking for partial labels
- BerHu loss for depth estimation
- Balanced loss weights based on data distribution

## Performance Requirements

### Target Metrics
- **Detection**: mAP@0.5 > 0.7, mAP@0.5:0.95 > 0.5
- **Segmentation**: Mask mAP@0.5 > 0.65, mAP@0.5:0.95 > 0.45  
- **Depth**: AbsRel < 0.15, RMSE < 5.0m, δ1 > 0.85

### Deployment Targets
- **Platform**: NVIDIA Jetson Orin Nano
- **Performance**: 30+ FPS at 640x640 resolution
- **Memory**: <6GB GPU memory usage
- **Power**: <15W power consumption

## Code Organization

### Directory Structure
```
safetrip/
├── data/                   # Dataset and parsers
├── models/                 # Model implementations
├── mediazen/evaluation/    # Evaluation scripts
├── visualizations/         # Output visualizations
├── docs/                   # Documentation
└── .cursor/rules/          # Development rules
```

### File Naming Conventions
- Model files: `safetrip_yolo_multitask.py`
- Training scripts: `train_multitask.py`
- Evaluation: Place in `mediazen/evaluation/` folder
- Configuration: YAML files for dataset and model configs

### Code Quality Standards
- Type hints for all function parameters
- Comprehensive error handling with try-except blocks
- Memory-efficient implementations
- Proper tensor dimension validation

## Development Workflow

### Phase-based Development
1. **Phase 1**: ✅ Base model architecture design
2. **Phase 2**: 🔄 Advanced training techniques implementation
3. **Phase 3**: 📋 TensorRT optimization and deployment

### Current Implementation Status
- ✅ Multi-task model architecture
- ✅ Custom depth head implementation  
- ✅ Basic training pipeline
- 🔄 Balanced batch sampling
- 🔄 Dynamic loss weighting
- 📋 TensorRT optimization

### Testing & Validation
- Unit tests for data loaders and model components
- Integration tests for training pipeline
- Performance benchmarking on Jetson hardware
- Real-world scenario validation

## Optimization Guidelines

### Memory Optimization
- Shared feature extraction across tasks
- Efficient tensor operations
- Gradient checkpointing if needed
- Proper CUDA memory management

### Inference Optimization
- TensorRT engine building with FP16/INT8 precision
- Input/output pipeline optimization
- Batch processing for multiple frames
- Post-processing acceleration

### Model Compression
- Knowledge distillation from larger models
- Pruning and quantization techniques
- Architecture optimization for mobile deployment

## Monitoring & Evaluation

### Training Monitoring
- Task-specific loss tracking
- Performance metrics per epoch
- Learning rate scheduling
- Gradient norm monitoring

### Model Evaluation
- Comprehensive metric calculation per task
- Cross-validation on different scenarios
- Real-time performance measurement
- Memory and power consumption tracking

### Logging Standards
- Structured logging with proper levels
- Experiment tracking with Weights & Biases
- Model checkpointing with best performance
- Detailed error reporting and debugging info

## Collaboration Guidelines

### Code Review Process
- Multi-task model changes require review
- Performance critical sections need benchmarking
- Memory usage validation for Jetson compatibility
- Documentation updates for new features

### Documentation Requirements
- Algorithm descriptions with mathematical formulations
- Performance benchmark results
- Deployment instructions for different platforms
- Troubleshooting guides for common issues

### Version Control
- Feature branches for major model changes
- Semantic versioning for model releases
- Tagged releases for deployment milestones
- Proper commit messages with scope indication

This comprehensive ruleset ensures consistent development practices while maintaining the multi-task nature and deployment requirements of the SafeTrip project.
