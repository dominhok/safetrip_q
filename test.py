"""
SafeTrip ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ í†µí•© í…ŒìŠ¤íŠ¸ - ì‹¤ì œ ë°ì´í„° ëŒ€ëŸ‰ í…ŒìŠ¤íŠ¸
"""

import sys
import torch
import numpy as np
from pathlib import Path
from typing import Dict, Optional
import traceback

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.append(str(project_root))

def test_model_creation():
    """ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("ğŸ”¨ ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸...")
    try:
        from model import create_model
        
        model = create_model(
            backbone_name='resnet34',
            num_classes=3,
            num_seg_classes=1,
            input_size=640,
            pretrained=False  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
        )
        
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"  âœ… ëª¨ë¸ ìƒì„± ì„±ê³µ")
        print(f"  ğŸ“Š ì „ì²´ íŒŒë¼ë¯¸í„°: {total_params:,}")
        print(f"  ğŸ“Š í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return False

def test_forward_pass():
    """ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸ - ëŒ€ëŸ‰ ì‹¤ì œ ë°ì´í„° ì‚¬ìš©"""
    print("\nğŸš€ ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸ (ëŒ€ëŸ‰ ë°ì´í„°)...")
    try:
        from model import create_model
        from data.dataset import create_dataloader
        
        model = create_model(pretrained=False)
        model.eval()
        
        # ë” ë§ì€ ìƒ˜í”Œê³¼ í° ë°°ì¹˜ í¬ê¸°ë¡œ í…ŒìŠ¤íŠ¸
        dataloader = create_dataloader(
            data_root='data',
            mode='train',
            batch_size=8,  # ë°°ì¹˜ í¬ê¸° ì¦ê°€
            num_workers=0,
            max_samples=50,  # ìƒ˜í”Œ ìˆ˜ ì¦ê°€
            target_tasks=['bbox', 'surface', 'depth']
        )
        
        print(f"  ğŸ” ë°ì´í„°ë¡œë” ìƒì„± ì™„ë£Œ, ì´ ë°°ì¹˜ ìˆ˜: {len(dataloader)}")
        
        # ì—¬ëŸ¬ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
        total_bbox_count = 0
        total_depth_count = 0
        
        for batch_idx, batch in enumerate(dataloader):
            if batch_idx >= 3:  # ì²˜ìŒ 3ê°œ ë°°ì¹˜ë§Œ í…ŒìŠ¤íŠ¸
                break
                
            images = batch['images']
            targets = batch['targets']
            
            with torch.no_grad():
                outputs = model(images)
            
            # BBox í†µê³„
            batch_bbox_count = sum(len(bbox) for bbox in targets['bboxes'])
            total_bbox_count += batch_bbox_count
            
            # Depth í†µê³„
            if 'depth_tensor' in targets and targets['depth_tensor'] is not None:
                batch_depth_count = len(targets['depth_indices'])
                total_depth_count += batch_depth_count
            else:
                batch_depth_count = 0
            
            print(f"\n  ğŸ“¦ ë°°ì¹˜ {batch_idx}:")
            print(f"    ì…ë ¥: {images.shape}")
            print(f"    BBox ê°œìˆ˜: {[len(bbox) for bbox in targets['bboxes']]} (ì´ {batch_bbox_count})")
            print(f"    Surface: {targets['surface'].shape}")
            print(f"    Depth ìƒ˜í”Œ: {batch_depth_count}ê°œ")
            
            if batch_bbox_count > 0:
                print(f"    ğŸ¯ BBox ë°ì´í„° ë°œê²¬!")
                # ì²« ë²ˆì§¸ bbox ìƒì„¸ ì •ë³´
                for i, bbox_list in enumerate(targets['bboxes']):
                    if len(bbox_list) > 0:
                        first_bbox = bbox_list[0]
                        print(f"      ìƒ˜í”Œ {i} ì²« ë²ˆì§¸ bbox: {first_bbox}")
        
        print(f"\n  âœ… ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        print(f"  ğŸ“Š ì´ BBox ê°œìˆ˜: {total_bbox_count}")
        print(f"  ğŸ“Š ì´ Depth ìƒ˜í”Œ: {total_depth_count}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ ìˆœì „íŒŒ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return False

def test_loss_computation():
    """ì†ì‹¤ ê³„ì‚° í…ŒìŠ¤íŠ¸ - ëŒ€ëŸ‰ ì‹¤ì œ ë°ì´í„° ì‚¬ìš©"""
    print("\nğŸ’” ì†ì‹¤ ê³„ì‚° í…ŒìŠ¤íŠ¸ (ëŒ€ëŸ‰ ë°ì´í„°)...")
    try:
        from model import create_model
        from data.dataset import create_dataloader
        
        model = create_model(pretrained=False)
        model.eval()
        
        # ë” ë§ì€ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸
        dataloader = create_dataloader(
            data_root='data',
            mode='train',
            batch_size=8,  # ë°°ì¹˜ í¬ê¸° ì¦ê°€
            num_workers=0,
            max_samples=50,  # ìƒ˜í”Œ ìˆ˜ ì¦ê°€
            target_tasks=['bbox', 'surface', 'depth']
        )
        
        # BBox ë°ì´í„°ê°€ ìˆëŠ” ë°°ì¹˜ ì°¾ê¸°
        bbox_batch_found = False
        
        for batch_idx, batch in enumerate(dataloader):
            images = batch['images']
            targets = batch['targets']
            
            # BBox ê°œìˆ˜ í™•ì¸
            batch_bbox_count = sum(len(bbox) for bbox in targets['bboxes'])
            
            if batch_bbox_count > 0:
                print(f"  ğŸ¯ BBox ë°ì´í„° ë°œê²¬! ë°°ì¹˜ {batch_idx}, BBox ê°œìˆ˜: {batch_bbox_count}")
                bbox_batch_found = True
                
                outputs = model(images)
                
                # ì†ì‹¤ ê³„ì‚°
                loss_dict = model.compute_loss(outputs, targets)
                
                print(f"  âœ… ì†ì‹¤ ê³„ì‚° ì„±ê³µ (BBox ë°ì´í„° í¬í•¨)")
                for name, loss in loss_dict.items():
                    if isinstance(loss, torch.Tensor):
                        print(f"    ğŸ“Š {name}: {loss.item():.4f}")
                    else:
                        print(f"    ğŸ“Š {name}: {loss:.4f}")
                
                # íƒ€ê²Ÿ ìƒì„¸ ë¶„ì„
                print(f"\n  ğŸ“¦ íƒ€ê²Ÿ ìƒì„¸ ë¶„ì„:")
                for i, bbox_list in enumerate(targets['bboxes']):
                    if len(bbox_list) > 0:
                        print(f"    ìƒ˜í”Œ {i}: {len(bbox_list)} BBox")
                        for j, bbox in enumerate(bbox_list[:3]):  # ì²˜ìŒ 3ê°œë§Œ
                            print(f"      BBox {j}: {bbox}")
                
                break
            
            if batch_idx >= 5:  # 5ê°œ ë°°ì¹˜ê¹Œì§€ë§Œ í™•ì¸
                break
        
        if not bbox_batch_found:
            print(f"  âš ï¸ BBox ë°ì´í„°ê°€ ìˆëŠ” ë°°ì¹˜ë¥¼ ì°¾ì§€ ëª»í•¨. ë” ë§ì€ ìƒ˜í”Œì´ í•„ìš”í•  ìˆ˜ ìˆìŒ.")
            
            # ê·¸ë˜ë„ ì¼ë°˜ ì†ì‹¤ ê³„ì‚° í…ŒìŠ¤íŠ¸
            batch = next(iter(dataloader))
            images = batch['images']
            targets = batch['targets']
            outputs = model(images)
            loss_dict = model.compute_loss(outputs, targets)
            
            print(f"  âœ… ì¼ë°˜ ì†ì‹¤ ê³„ì‚° ì„±ê³µ")
            for name, loss in loss_dict.items():
                if isinstance(loss, torch.Tensor):
                    print(f"    ğŸ“Š {name}: {loss.item():.4f}")
                else:
                    print(f"    ğŸ“Š {name}: {loss:.4f}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ ì†ì‹¤ ê³„ì‚° ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return False

def test_dataset_statistics():
    """ë°ì´í„°ì…‹ í†µê³„ ë¶„ì„ - ì‹¤ì œ ë°ì´í„° ë¶„í¬ í™•ì¸"""
    print("\nğŸ“Š ë°ì´í„°ì…‹ í†µê³„ ë¶„ì„...")
    try:
        from data.dataset import SafeTripMultiTaskDataset
        
        # ë” ë§ì€ ìƒ˜í”Œë¡œ ë°ì´í„°ì…‹ ìƒì„±
        dataset = SafeTripMultiTaskDataset(
            data_root='data',
            mode='train',
            max_samples=100,  # ìƒ˜í”Œ ìˆ˜ ì¦ê°€
            target_tasks=['bbox', 'surface', 'depth'],
            augment=False
        )
        
        print(f"  âœ… ë°ì´í„°ì…‹ ìƒì„± ì„±ê³µ: {len(dataset)} ìƒ˜í”Œ")
        
        # ë°ì´í„°ì…‹ í†µê³„
        bbox_samples = 0
        surface_samples = 0
        depth_samples = 0
        total_bboxes = 0
        total_polygons = 0
        
        print(f"  ğŸ” ì „ì²´ ìƒ˜í”Œ ë¶„ì„ ì¤‘...")
        
        for i in range(min(50, len(dataset))):  # ì²˜ìŒ 50ê°œ ìƒ˜í”Œ ë¶„ì„
            try:
                sample = dataset[i]
                
                # BBox í™•ì¸
                if len(sample['targets']['bbox_labels']) > 0:
                    bbox_samples += 1
                    total_bboxes += len(sample['targets']['bbox_labels'])
                
                # Surface í™•ì¸
                if len(sample['targets']['polygons']) > 0:
                    surface_samples += 1
                    total_polygons += len(sample['targets']['polygons'])
                
                # Depth í™•ì¸
                if sample['targets']['depth'] is not None:
                    depth_samples += 1
                    
            except Exception as e:
                print(f"    âš ï¸ ìƒ˜í”Œ {i} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        print(f"\n  ğŸ“Š ë°ì´í„° ë¶„í¬ (ì²˜ìŒ 50ê°œ ìƒ˜í”Œ):")
        print(f"    BBox ìƒ˜í”Œ: {bbox_samples}/50 ({bbox_samples/50*100:.1f}%)")
        print(f"    Surface ìƒ˜í”Œ: {surface_samples}/50 ({surface_samples/50*100:.1f}%)")
        print(f"    Depth ìƒ˜í”Œ: {depth_samples}/50 ({depth_samples/50*100:.1f}%)")
        print(f"    ì´ BBox ìˆ˜: {total_bboxes}")
        print(f"    ì´ Polygon ìˆ˜: {total_polygons}")
        
        # BBoxê°€ ìˆëŠ” ìƒ˜í”Œ ì°¾ì•„ì„œ ìƒì„¸ ì •ë³´ ì¶œë ¥
        if bbox_samples > 0:
            print(f"\n  ğŸ¯ BBox ìƒ˜í”Œ ìƒì„¸ ë¶„ì„:")
            bbox_found = 0
            for i in range(len(dataset)):
                if bbox_found >= 3:  # ì²˜ìŒ 3ê°œë§Œ
                    break
                    
                try:
                    sample = dataset[i]
                    if len(sample['targets']['bbox_labels']) > 0:
                        bbox_found += 1
                        print(f"    ìƒ˜í”Œ {i}: {len(sample['targets']['bbox_labels'])} BBox")
                        print(f"      BBox ì¢Œí‘œ: {sample['targets']['bboxes'][:3]}")  # ì²˜ìŒ 3ê°œë§Œ
                        print(f"      BBox ë¼ë²¨: {sample['targets']['bbox_labels'][:3]}")
                except Exception as e:
                    continue
        
        return True
        
    except Exception as e:
        print(f"  âŒ ë°ì´í„°ì…‹ í†µê³„ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return False

def test_dataset_compatibility():
    """ë°ì´í„°ì…‹ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ - ëŒ€ëŸ‰ ìƒ˜í”Œ"""
    print("\nğŸ“¦ ë°ì´í„°ì…‹ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸...")
    try:
        from data.dataset import SafeTripMultiTaskDataset, create_dataloader
        
        # ë” ë§ì€ ìƒ˜í”Œë¡œ ë°ì´í„°ì…‹ ìƒì„±
        dataset = SafeTripMultiTaskDataset(
            data_root='data',
            mode='train',
            max_samples=100,  # ìƒ˜í”Œ ìˆ˜ ì¦ê°€
            target_tasks=['bbox', 'surface', 'depth'],
            augment=False
        )
        
        print(f"  âœ… ë°ì´í„°ì…‹ ìƒì„± ì„±ê³µ: {len(dataset)} ìƒ˜í”Œ")
        
        # ë°ì´í„°ì…‹ í†µê³„ ì¶œë ¥
        stats = dataset.get_statistics()
        print(f"  ğŸ“Š íƒœìŠ¤í¬ ì»¤ë²„ë¦¬ì§€:")
        print(f"    BBox: {stats['task_coverage']['bbox']} / {stats['total_samples']}")
        print(f"    Surface: {stats['task_coverage']['surface']} / {stats['total_samples']}")
        print(f"    Depth: {stats['task_coverage']['depth']} / {stats['total_samples']}")
        
        # ë” í° ë°°ì¹˜ë¡œ ë°ì´í„°ë¡œë” ìƒì„±
        dataloader = create_dataloader(
            data_root='data',
            mode='train',
            batch_size=8,  # ë°°ì¹˜ í¬ê¸° ì¦ê°€
            num_workers=0,
            max_samples=100,  # ìƒ˜í”Œ ìˆ˜ ì¦ê°€
            target_tasks=['bbox', 'surface', 'depth']
        )
        
        # ë°°ì¹˜ í…ŒìŠ¤íŠ¸
        batch = next(iter(dataloader))
        
        print(f"  âœ… ë°ì´í„°ë¡œë” ì„±ê³µ")
        print(f"  ğŸ“ ë°°ì¹˜ ì´ë¯¸ì§€: {batch['images'].shape}")
        print(f"  ğŸ“Š BBox ê°œìˆ˜: {[len(bbox_list) for bbox_list in batch['targets']['bboxes']]}")
        print(f"  ğŸ“Š Surface í˜•íƒœ: {batch['targets']['surface'].shape}")
        if 'depth_tensor' in batch['targets'] and batch['targets']['depth_tensor'] is not None:
            print(f"  ğŸ“Š Depth tensor í˜•íƒœ: {batch['targets']['depth_tensor'].shape}")
            print(f"  ğŸ“Š Depth ìœ íš¨ ì¸ë±ìŠ¤: {batch['targets']['depth_indices']}")
        else:
            print(f"  ğŸ“Š Depth: í•´ë‹¹ ë°°ì¹˜ì— depth ë°ì´í„° ì—†ìŒ")
        
        return True
        
    except Exception as e:
        print(f"  âŒ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return False

def test_training_step():
    """í•™ìŠµ ìŠ¤í… í…ŒìŠ¤íŠ¸ - ëŒ€ëŸ‰ ë°ì´í„°ë¡œ ì‹¤ì œ í•™ìŠµ"""
    print("\nğŸ“ í•™ìŠµ ìŠ¤í… í…ŒìŠ¤íŠ¸ (ëŒ€ëŸ‰ ë°ì´í„°)...")
    try:
        from model import create_model
        from data.dataset import create_dataloader
        import torch.optim as optim
        
        # ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì €
        model = create_model(pretrained=False)
        optimizer = optim.AdamW(model.parameters(), lr=1e-4)
        
        # ë” ë§ì€ ìƒ˜í”Œë¡œ ë°ì´í„°ë¡œë” ìƒì„±
        dataloader = create_dataloader(
            data_root='data',
            mode='train',
            batch_size=8,  # ë°°ì¹˜ í¬ê¸° ì¦ê°€
            num_workers=0,
            max_samples=100,  # ìƒ˜í”Œ ìˆ˜ ì¦ê°€
            target_tasks=['bbox', 'surface', 'depth']
        )
        
        print(f"  ğŸ” ì´ {len(dataloader)}ê°œ ë°°ì¹˜ë¡œ í•™ìŠµ í…ŒìŠ¤íŠ¸")
        
        # ì—¬ëŸ¬ ë°°ì¹˜ë¡œ í•™ìŠµ ìŠ¤í… í…ŒìŠ¤íŠ¸
        bbox_training_done = False
        
        for batch_idx, batch in enumerate(dataloader):
            if batch_idx >= 3:  # ì²˜ìŒ 3ê°œ ë°°ì¹˜ë§Œ í…ŒìŠ¤íŠ¸
                break
                
            images = batch['images']
            targets = batch['targets']
            
            # BBox ê°œìˆ˜ í™•ì¸
            batch_bbox_count = sum(len(bbox) for bbox in targets['bboxes'])
            
            print(f"\n  ğŸ“¦ ë°°ì¹˜ {batch_idx}: BBox {batch_bbox_count}ê°œ")
            
            # Forward
            outputs = model(images)
            
            # Loss ê³„ì‚°
            loss_dict = model.compute_loss(outputs, targets)
            total_loss = loss_dict['total_loss']
            
            print(f"    ì†ì‹¤ (í•™ìŠµ ì „):")
            for name, loss in loss_dict.items():
                if isinstance(loss, torch.Tensor):
                    print(f"      {name}: {loss.item():.4f}")
                else:
                    print(f"      {name}: {loss:.4f}")
            
            # Backward
            if isinstance(total_loss, torch.Tensor):
                optimizer.zero_grad()
                total_loss.backward()
                optimizer.step()
                
                # í•™ìŠµ í›„ ë‹¤ì‹œ ê³„ì‚°
                with torch.no_grad():
                    outputs_after = model(images)
                    loss_dict_after = model.compute_loss(outputs_after, targets)
                
                print(f"    ì†ì‹¤ (í•™ìŠµ í›„):")
                for name, loss in loss_dict_after.items():
                    if isinstance(loss, torch.Tensor):
                        print(f"      {name}: {loss.item():.4f}")
                    else:
                        print(f"      {name}: {loss:.4f}")
                
                if batch_bbox_count > 0:
                    bbox_training_done = True
                    print(f"    ğŸ¯ BBox ë°ì´í„°ë¡œ í•™ìŠµ ì™„ë£Œ!")
        
        if bbox_training_done:
            print(f"\n  âœ… BBox ë°ì´í„° í¬í•¨ í•™ìŠµ ìŠ¤í… ì„±ê³µ")
        else:
            print(f"\n  âš ï¸ BBox ë°ì´í„° ì—†ì´ í•™ìŠµ ì™„ë£Œ")
        
        return True
        
    except Exception as e:
        print(f"  âŒ í•™ìŠµ ìŠ¤í… ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return False

def test_depth_data_availability():
    """Depth ë°ì´í„° ê°€ìš©ì„± í™•ì¸"""
    print("\nğŸ¯ Depth ë°ì´í„° ê°€ìš©ì„± í™•ì¸...")
    try:
        from data.dataset import SafeTripMultiTaskDataset
        
        # Depth íƒœìŠ¤í¬ë§Œ í¬í•¨
        dataset = SafeTripMultiTaskDataset(
            data_root='data',
            mode='train',
            max_samples=50,  # ìƒ˜í”Œ ìˆ˜ ì¦ê°€
            target_tasks=['depth'],  # Depthë§Œ
            augment=False
        )
        
        print(f"  âœ… Depth ì „ìš© ë°ì´í„°ì…‹: {len(dataset)} ìƒ˜í”Œ")
        
        # Depth ìƒ˜í”Œ í†µê³„
        depth_count = 0
        for i in range(min(20, len(dataset))):
            try:
                sample = dataset[i]
                if sample['targets']['depth'] is not None:
                    depth_count += 1
                    if depth_count <= 3:  # ì²˜ìŒ 3ê°œë§Œ ìƒì„¸ ì¶œë ¥
                        depth_map = sample['targets']['depth']
                        print(f"    ìƒ˜í”Œ {i}: Depth {depth_map.shape}, ë²”ìœ„: {depth_map.min():.1f}~{depth_map.max():.1f}")
            except Exception as e:
                print(f"    âš ï¸ ìƒ˜í”Œ {i} ì˜¤ë¥˜: {e}")
        
        print(f"  ğŸ“Š Depth ìƒ˜í”Œ: {depth_count}/20")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Depth ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return False

def main():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ§ª SafeTrip ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ ëŒ€ëŸ‰ ë°ì´í„° í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    print("="*60)
    
    tests = [
        test_model_creation,
        test_dataset_statistics,  # í†µê³„ë¶€í„° í™•ì¸
        test_forward_pass,
        test_loss_computation,
        test_dataset_compatibility,
        test_training_step,
        test_depth_data_availability
    ]
    
    results = []
    for test_func in tests:
        try:
            result = test_func()
            results.append((test_func.__name__, result))
        except Exception as e:
            print(f"âŒ {test_func.__name__} í…ŒìŠ¤íŠ¸ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            results.append((test_func.__name__, False))
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "="*60)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
        print(f"{status} {test_name}")
    
    print(f"\nğŸ¯ ì „ì²´ ê²°ê³¼: {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼")
    
    if passed == total:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ì‹¤ì œ ë°ì´í„°ë¡œ ì™„ì „ ë™ì‘ í™•ì¸ë¨")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì¶”ê°€ ë””ë²„ê¹… í•„ìš”")

if __name__ == "__main__":
    main() 